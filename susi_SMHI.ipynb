{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciatlizating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "#from pyproj import Proj\n",
    "\n",
    "# Global definitions\n",
    "entryPoint = 'https://opendata-download-metobs.smhi.se/api'\n",
    "\n",
    "output_folder = 'weather_output/2022_12_02_weather/'\n",
    "if not os.path.exists(output_folder): os.mkdir(output_folder)\n",
    "\n",
    "date_start = '2000-01-01'\n",
    "date_end = '2021-12-31'\n",
    "stations_nearby = 10\n",
    "\n",
    "# reading sites\n",
    "wStations = pd.DataFrame(\n",
    "    {\"varType\": [\"t_mean\", \"t_max\", \"t_min\", \"rainfall\", \"radiation\", \"hpa\", \"humidity\" ],\n",
    "    \"stationType\": [\"Temp\", \"Temp\", \"Temp\", \"Precipitation\", \"GlobalRad\", \"AirPreassure\", \"humidity\"],\n",
    "    \"parameter\": [2, 20, 19, 5, 11, 9, 6]})\n",
    "\n",
    "#version = 1.0\n",
    "#parameter = 9\n",
    "#station = 188790\n",
    "#ext = 'csv'\n",
    "\n",
    "wStations = wStations.loc[~wStations['varType'].isin(['hpa'])]  # remove the AirPreassure\n",
    "#wStations = wStations[wStations['varType'] == 'Temp'] #try only humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading distance matrix for Ulf Stations, the station_dm index is manual for now but shoud come from a function\n",
    "# NOTA, AUTOMATIZAR LA DISTANCE MATRIX PARA EVITAR ERROR EN NOMBRES\n",
    "dm_dir = \"shapefiles/distance_matrix/\"\n",
    "station_dm = os.listdir(dm_dir)\n",
    "distanceMatrix = {\n",
    "\"AirPreassure\": pd.read_csv(dm_dir + station_dm[0], sep=',', encoding='utf-8'),\n",
    "\"GlobalRad\": pd.read_csv(dm_dir + station_dm[1], sep=',', encoding='utf-8'),\n",
    "\"humidity\": pd.read_csv(dm_dir + station_dm[2], sep=',', encoding='utf-8'),\n",
    "\"Precipitation\": pd.read_csv(dm_dir + station_dm[3], sep=',', encoding='utf-8'),\n",
    "'Temp': pd.read_csv(dm_dir + station_dm[4], sep=',', encoding='utf-8')\n",
    "\n",
    "}\n",
    "\n",
    "### manual entry of the site description\n",
    "site_description = pd.read_csv(\"shapefiles/ulf_sites_simple.csv\", sep=',', encoding='latin1')\n",
    "#distanceMatrix.keys()\n",
    "\n",
    "#\"parameter\": [2, 20, 19, 5, 'GlobalRLink', 9]})\n",
    "# sites exracted from distance matrix (not the optimal way but it works for Uls Sites)\n",
    "sites = distanceMatrix[\"Precipitation\"][\"InputID\"].unique()\n",
    "\n",
    "\n",
    "#sites = sites[[0]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AirPreassure', 'GlobalRad', 'humidity', 'Precipitation', 'Temp'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distanceMatrix.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1_Bjdamm', '03_Korpis', '04_Fröjered', '05_SträRed', '06_Risabo',\n",
       "       '07_Rothult', '08_Ydreham', '09_Gröngöl', '10_Hällehult',\n",
       "       '11_Ökalix', '12_Ökalix', '13_Ökalix', '14_Höglund', '15_Jörnmark'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISTANCE MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMHI api\n",
    "# https://opendata.smhi.se/apidocs/metobs/index.html\n",
    "#https://opendata-download-metobs.smhi.se/api/version/1.0/parameter/9/station/188790/period/corrected-archive/data.csv\n",
    "\n",
    "#Syntax\n",
    "# GET /api/version/{version}/parameter/{parameter}.{ext}?measuringStations={measuringStations}\n",
    "\n",
    "def readData(station, parameterLabel, date_start, date_end, version = 1.0, ext = 'csv'):\n",
    "    #print(f\"{station}.{ext}\")\n",
    "    #print( wStations.loc[wStations.varType == parameterLabel])\n",
    "\n",
    "    parameter = wStations.loc[wStations.varType == parameterLabel].parameter.item() #assign code to parameter label\n",
    "    #reads the air pressure data, and returns a dataframe with daily average values\n",
    "    file = f\"{entryPoint}/version/{version}/parameter/{parameter}/station/{station}/period/corrected-archive/data.{ext}\"\n",
    "\n",
    "    r = requests.get(file)\n",
    "    dumpFile = f\"dump/{parameter}_{station}.{ext}\"\n",
    "    with open(dumpFile, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "\n",
    "    skp = pd.read_csv(file, sep='\\t|;', engine='python', names=range(50), skip_blank_lines=False).iloc[1:20,[0]]    #read file to find the first row\n",
    "        #if len(skp) == 0: return 0\n",
    "    datum_skp = skp[skp[0].str.contains(\"Datum\", na = False)].index.values[0]   #define the first row\n",
    "\n",
    "    if parameter == 9:  #9 AirPressure\n",
    "        ds = pd.read_csv(file, sep='\\t|;', engine='python', skiprows=datum_skp).iloc[:,[0,2]]\n",
    "        ds = ds.groupby('Datum', as_index=False).mean()\n",
    "        \n",
    "    elif parameter == 6:  #6 Humidity\n",
    "        # the next try and except is not mandatory, it is for testing proposes.\n",
    "        try: \n",
    "            ds = pd.read_csv(file, sep='\\t|;', engine='python', skiprows=datum_skp).iloc[:,[0,2]]\n",
    "            ds = ds.groupby('Datum', as_index=False).mean()\n",
    "            status = \"ok\"\n",
    "        except:\n",
    "            print(f\"error reading file {file}, \")\n",
    "            status=\"fail\"\n",
    "\n",
    "        r = requests.get(file)\n",
    "        dumpFile = f\"dump/{parameter}_{station}_{status}.{ext}\"\n",
    "        with open(dumpFile, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "\n",
    "            ##########################################################################################\n",
    "\n",
    "\n",
    "    elif parameter == 11:  #11 GlobalRad\n",
    "        ds = pd.read_csv(file, sep='\\t|;', engine='python', skiprows=datum_skp).iloc[:,[0,2]]\n",
    "        ds = ds.groupby('Datum', as_index=False).sum()  # sum watt hour to day\n",
    "        ds.iloc[:,[1]] = ds.iloc[:,[1]] * 3.6  # watt to Joules\n",
    "        \n",
    "    else:  #rainfall and temperature\n",
    "        ds = pd.read_csv(file, sep='\\t|;', engine='python', skiprows=datum_skp).iloc[:,[2,3]]\n",
    "\n",
    "    ds.columns = ['Datum', parameterLabel]  #rename headers\n",
    "    ds.Datum = pd.to_datetime(ds.Datum, infer_datetime_format=True).dt.strftime('%Y-%m-%d')\n",
    "    ds.set_index('Datum', drop=True, inplace=True)\n",
    "\n",
    "    # some tyding\n",
    "    try: ds = ds.loc[(ds.index >= date_start) & (ds.index <= date_end)]\n",
    "    except: \n",
    "        ds = pd.DataFrame({'Datum':date_start, parameterLabel:None})\n",
    "        ds.set_index('Datum', drop=True, inplace=True)\n",
    "\n",
    "    ds = ds[~ds.index.duplicated(keep='first')]  #delete the duplicated records\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading staitos distance matrix\n",
    "\n",
    "for now it is fixed but it can be automated for any coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrateData (site, distanceMatrix, date_start, date_end, stations_nearby=1, wStations=wStations):\n",
    "# the function iterates on varType [\"hpa\", \"radiation\", \"rainfall\", \"t_mean\", \"t_max\", \"t_min\"]\n",
    "# depends on the varType it selects the station type group, ex t_mean uses Temperature station\n",
    "# then selects n stations nearby, gets the data and integrate it\n",
    "    stReaded = pd.DataFrame(columns= ['varType', 'nStations'])\n",
    "\n",
    "    if stations_nearby < 1: stations_nearby = 1\n",
    "    stationDataFilled = {}\n",
    "    for varType in wStations.varType:\n",
    "        #print(f\"varType {wStations[wStations.varType == varType]}, \")\n",
    "        st = wStations[wStations.varType == varType].stationType.item() # gets the station type, related to varType\n",
    "        dmType = distanceMatrix[st]  #filter the distance matrix by station type\n",
    "        dmSite=dmType.loc[dmType[\"InputID\"] == site].sort_values(by=\"Distance\").head(stations_nearby)  #gets the top n nearest sations for the site\n",
    "        stationData = {}\n",
    "        stationDataGaps = pd.DataFrame(data = {varType: None, 'Datum':pd.date_range(date_start, date_end, freq=\"D\").strftime('%Y-%m-%d')})\n",
    "        stationDataGaps.set_index('Datum', drop=True, inplace=True)\n",
    "\n",
    "        for stationPosition in range(stations_nearby):   #using for cycle\n",
    "#        stationPosition = 0\n",
    "#        while True: \n",
    "            stationID = dmSite[\"TargetID\"].iloc[stationPosition]\n",
    "            stationData[stationPosition] = readData(stationID, varType, date_start, date_end) # reads station data\n",
    "            stationDataGaps = stationDataGaps.combine_first(stationData[stationPosition])\n",
    "            if stationDataGaps.isnull().sum(axis = 1).sum() == 0: break\n",
    "#            stationPosition += 1\n",
    "#            if (stationPosition > stations_nearby) or (stationDataGaps.isnull().sum(axis = 1).sum() == 0): break\n",
    "\n",
    "        stationDataFilled[varType] = stationDataGaps\n",
    "\n",
    "        stReaded = pd.concat([stReaded, pd.DataFrame({'varType':[varType], 'nStations':[stationPosition +1]})], axis=0, ignore_index=True)\n",
    "        print(f\"{varType}: {stationPosition +1}\", end=' ')\n",
    "\n",
    "        #stationDataGaps.to_csv(output_folder+site+'_'+varType+'_weather.csv', sep=';', index=False)\n",
    "\n",
    "\n",
    "\n",
    "    ## hacer join de los stationDataFilled para hacer el dataset final.\n",
    "    #return stationDataFilled\n",
    "    stationDataConcat = pd.concat(stationDataFilled, axis=1).droplevel(0, axis=1)\n",
    "    #stationDataConcat = stationDataConcat.loc[:,~stationDataConcat.columns.duplicated()]\n",
    "    return stationDataConcat, stReaded\n",
    "    # return stationDataFilled  #for testing proposes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data (sw, mv=None):\n",
    "    # mv: missing_value_df\n",
    "    check = 0 if mv is None else 1\n",
    "    percent_missing = sw.isnull().sum() * 100 / len(sw)\n",
    "    if check == 1:\n",
    "        tmv = pd.DataFrame({'varType': sw.columns,\n",
    "                            'percent_missing': percent_missing})\n",
    "        tmv.set_index('varType', drop=False ,inplace=True)\n",
    "        tmv = tmv[~tmv.index.isin(mv.index)]\n",
    "        mv = pd.concat([mv, tmv],ignore_index=False)\n",
    "    else:\n",
    "        mv = pd.DataFrame({'varType': sw.columns,\n",
    "                'percent_missing': percent_missing})\n",
    "        mv.set_index('varType', drop=False, inplace=True)\n",
    "    return mv, percent_missing  \n",
    "\n",
    "\n",
    "def vaporPressure (tempC, RH):\n",
    "    from math import exp\n",
    "    to_hecto = 0.01\n",
    "    es = 611* exp( (17.27 * tempC) / ( 237.2 + tempC))\n",
    "    e = (es * RH)/ 100\n",
    "    e_hPa = e * to_hecto\n",
    "    return e_hPa\n",
    "\n",
    "def calc_hPa(ds, stReaded):\n",
    "    # calculate HPA\n",
    "    #ds['hpa'] = 1\n",
    "    ds['hpa'] = ds.apply(lambda ds : vaporPressure(ds['t_mean'], ds['humidity']), axis=1)\n",
    "    \n",
    "    stReaded.index = stReaded.varType\n",
    "    stReaded = pd.concat([stReaded, pd.DataFrame({'varType':['hpa'], 'nStations':['calculated']})], axis=0, ignore_index=True)\n",
    "    return ds, stReaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_mean: 7 t_max: 7 t_min: 7 rainfall: 9 radiation: 2 humidity: 10 \n",
      " site 01_Bjdamm: \tOK -- from 2000-01-01 to 2021-12-31 -- (8036 days, 22 years) max 10 stations nearby\n",
      "t_mean: 4 t_max: 4 t_min: 4 rainfall: 3 radiation: 1 humidity: 10 \n",
      " site 03_Korpis: \tOK -- from 2000-01-01 to 2021-12-31 -- (8036 days, 22 years) max 10 stations nearby\n",
      "t_mean: 4 t_max: 4 t_min: 4 rainfall: 2 radiation: 1 humidity: 10 \n",
      " site 04_Fröjered: \tOK -- from 2000-01-01 to 2021-12-31 -- (8036 days, 22 years) max 10 stations nearby\n",
      "t_mean: 1 t_max: 1 t_min: 1 rainfall: 3 radiation: 2 humidity: 10 \n",
      " site 05_SträRed: \tOK -- from 2000-01-01 to 2021-12-31 -- (8036 days, 22 years) max 10 stations nearby\n",
      "t_mean: 6 t_max: 6 t_min: 6 rainfall: 3 radiation: 1 humidity: 10 \n",
      " site 06_Risabo: \tOK -- from 2000-01-01 to 2021-12-31 -- (8036 days, 22 years) max 10 stations nearby\n",
      "t_mean: 5 t_max: 5 t_min: 5 rainfall: 2 radiation: 2 humidity: 10 \n",
      " site 07_Rothult: \tOK -- from 2000-01-01 to 2021-12-31 -- (8036 days, 22 years) max 10 stations nearby\n",
      "t_mean: 4 t_max: 4 t_min: 4 rainfall: 3 radiation: 3 humidity: 10 \n",
      " site 08_Ydreham: \tOK -- from 2000-01-01 to 2021-12-31 -- (8036 days, 22 years) max 10 stations nearby\n",
      "t_mean: 9 t_max: 9 t_min: 9 rainfall: 3 radiation: 1 humidity: 10 \n",
      " site 09_Gröngöl: \tOK -- from 2000-01-01 to 2021-12-31 -- (8036 days, 22 years) max 10 stations nearby\n",
      "t_mean: 2 t_max: 2 t_min: 2 rainfall: 4 radiation: 1 humidity: 10 \n",
      " site 10_Hällehult: \tOK -- from 2000-01-01 to 2021-12-31 -- (8036 days, 22 years) max 10 stations nearby\n",
      "t_mean: 10 t_max: 10 t_min: 10 rainfall: 1 radiation: 1 humidity: 10 \n",
      " site 11_Ökalix: \tOK -- from 2000-01-01 to 2021-12-31 -- (8036 days, 22 years) max 10 stations nearby\n",
      "t_mean: 10 t_max: 10 t_min: 10 rainfall: 1 radiation: 1 humidity: 10 \n",
      " site 12_Ökalix: \tOK -- from 2000-01-01 to 2021-12-31 -- (8036 days, 22 years) max 10 stations nearby\n",
      "t_mean: 10 t_max: 10 t_min: 10 rainfall: 1 radiation: 1 humidity: 10 \n",
      " site 13_Ökalix: \tOK -- from 2000-01-01 to 2021-12-31 -- (8036 days, 22 years) max 10 stations nearby\n",
      "t_mean: 10 t_max: 10 t_min: 10 rainfall: 2 radiation: 1 humidity: 10 \n",
      " site 14_Höglund: \tOK -- from 2000-01-01 to 2021-12-31 -- (8036 days, 22 years) max 10 stations nearby\n",
      "t_mean: 8 t_max: 8 t_min: 8 rainfall: 2 radiation: 1 humidity: 10 \n",
      " site 15_Jörnmark: \tOK -- from 2000-01-01 to 2021-12-31 -- (8036 days, 22 years) max 10 stations nearby\n"
     ]
    }
   ],
   "source": [
    "summary_all = {}\n",
    "#main run\n",
    "for site in sites:\n",
    "    #integratedData = integrateData(site, distanceMatrix, stations_nearby, date_start, date_end)\n",
    "    #integrateData (site, distanceMatrix, date_start, date_end, stations_nearby=1, wStations=wStations):\n",
    "    try:\n",
    "        sw, stReaded = integrateData(site, distanceMatrix, date_start, date_end, stations_nearby)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        break\n",
    "    #Check nd percentage\n",
    "    missing_value_df, percent_missing = missing_data(sw)\n",
    "    sw.index =pd.to_datetime(sw.index)  #correct index to date\n",
    "\n",
    "    #RESAMPLE column if nd found\n",
    "    for col in missing_value_df.varType:\n",
    "        if missing_value_df[missing_value_df.varType == col].percent_missing[0] > 0:\n",
    "            sw[col] = sw[col].resample('1D').mean().interpolate()\n",
    "            missing_value_df.at[col, 'resampled'] = True\n",
    "        else:  missing_value_df.at[col, 'resampled'] = False\n",
    "\n",
    "# calculate columns\n",
    "    sw, stReadedc = calc_hPa(sw, stReaded)\n",
    "    #missing_value_df, percent_missing = missing_data(sw, missing_value_df)\n",
    "\n",
    "\n",
    "    summary = pd.concat([missing_value_df, stReaded.nStations], axis=1)\n",
    "    summary['site'] = site\n",
    "    summary_all['site'] = summary \n",
    "\n",
    "    # get the data in structure\n",
    "    integratedData = pd.DataFrame({\n",
    "        'OmaTunniste': \"\",\n",
    "        'OmaIt': \"\",\n",
    "        'OmaPohjoinen': \"\",\n",
    "        'Kunta': site,\n",
    "        'siteid': site.split('-')[0],\n",
    "        'aika':  pd.to_datetime(sw.index).strftime('%Y%m%d'),\n",
    "        'vuosi':  pd.to_datetime(sw.index).strftime('%Y'),\n",
    "        'kk': pd.to_datetime(sw.index).strftime('%m'),\n",
    "        'paiva': pd.to_datetime(sw.index).strftime('%d'),\n",
    "        'longitude': site_description[site_description.cod_name == site].iloc[0].X,\n",
    "        'latitude': site_description[site_description.cod_name == site].iloc[0].Y,\n",
    "        't_mean': pd.to_numeric(sw.t_mean),\n",
    "        't_max': pd.to_numeric(sw.t_max),\n",
    "        't_min': pd.to_numeric(sw.t_min),\n",
    "        'rainfall': pd.to_numeric(sw.rainfall),\n",
    "        'radiation': pd.to_numeric(sw.radiation).round(2),\n",
    "        'hpa': pd.to_numeric(sw.hpa).round(2)\n",
    "    })\n",
    "    #write the data missing value table\n",
    "    summary.to_csv(output_folder+'_summary_'+site+'_weather.csv', sep=';', index=False)\n",
    "    integratedData.to_csv(output_folder+site+'_weather.csv', sep=';', index=False)\n",
    "    print(f\"\\n site {site}: \\tOK -- from { date_start} to {date_end} -- ({len(sw)} days, {round((len(sw) / 365.25))} years) max {stations_nearby} stations nearby\")\n",
    "    #except: print(f\"site {site}: \\tERROR\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_mean: 8 t_max: 8 t_min: 8 rainfall: 2 radiation: 1 humidity: 10 "
     ]
    }
   ],
   "source": [
    "site = '15_Jörnmark'\n",
    "sw, stReaded = integrateData(site, distanceMatrix, date_start, date_end, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_mean</th>\n",
       "      <th>t_max</th>\n",
       "      <th>t_min</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>radiation</th>\n",
       "      <th>humidity</th>\n",
       "      <th>hpa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>-16.7</td>\n",
       "      <td>-13.1</td>\n",
       "      <td>-22.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>43.92</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>1.404148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-02</th>\n",
       "      <td>-3.6</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-13.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>45.72</td>\n",
       "      <td>92.541667</td>\n",
       "      <td>4.333035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>-7.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-13.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>226.08</td>\n",
       "      <td>89.625000</td>\n",
       "      <td>3.238916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-8.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.52</td>\n",
       "      <td>91.916667</td>\n",
       "      <td>4.849062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>-8.2</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>-14.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>348.12</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>2.732441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-27</th>\n",
       "      <td>-17.1</td>\n",
       "      <td>-15.7</td>\n",
       "      <td>-18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.308</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.277676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28</th>\n",
       "      <td>-11.8</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-17.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>95.832</td>\n",
       "      <td>88.583333</td>\n",
       "      <td>2.191513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29</th>\n",
       "      <td>-6.4</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>97.884</td>\n",
       "      <td>93.833333</td>\n",
       "      <td>3.551556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30</th>\n",
       "      <td>-8.6</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>87.912</td>\n",
       "      <td>92.166667</td>\n",
       "      <td>2.940715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>-10.7</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.292</td>\n",
       "      <td>87.291667</td>\n",
       "      <td>2.358831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8036 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           t_mean t_max t_min rainfall radiation   humidity       hpa\n",
       "Datum                                                                \n",
       "2000-01-01  -16.7 -13.1 -22.6      2.2     43.92  85.000000  1.404148\n",
       "2000-01-02   -3.6  -0.5 -13.7      7.0     45.72  92.541667  4.333035\n",
       "2000-01-03   -7.0  -0.5 -13.3      3.2    226.08  89.625000  3.238916\n",
       "2000-01-04   -2.0  -0.8  -8.1      0.0     20.52  91.916667  4.849062\n",
       "2000-01-05   -8.2  -1.9 -14.1      0.0    348.12  83.000000  2.732441\n",
       "...           ...   ...   ...      ...       ...        ...       ...\n",
       "2021-12-27  -17.1 -15.7 -18.8      0.0   160.308  80.000000  1.277676\n",
       "2021-12-28  -11.8  -9.0 -17.9      2.1    95.832  88.583333  2.191513\n",
       "2021-12-29   -6.4  -4.3  -9.0      0.4    97.884  93.833333  3.551556\n",
       "2021-12-30   -8.6  -6.2 -10.6      0.9    87.912  92.166667  2.940715\n",
       "2021-12-31  -10.7  -7.5 -12.7      0.0   149.292  87.291667  2.358831\n",
       "\n",
       "[8036 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "519251286f1405f32e6cff55ed69bb1b79a31577ae9185a3274505f77a5b17cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
